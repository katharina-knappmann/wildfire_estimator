{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Data_Preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/knattarina/wildfire_challenge/blob/main/Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIZbDkz-dC6J"
      },
      "source": [
        "##### IMPORTS AND SETUP #####\n",
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "#from project_lib import Project\n",
        "#from pyspark.sql import SparkSession\n",
        "from google.colab import drive\n",
        "\n",
        "#project = Project(sc,\"ff75f9c0-4f85-495d-bbc1-6305f6b1dbb8\", \"p-12f1b4bbd0ab3b00eacd4ce1201f20ce039b72ec\")\n",
        "#spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVzy9D46e0sa",
        "outputId": "5514af7a-dea6-45fe-bd92-eeb4aca647b0"
      },
      "source": [
        "drive.mount('/content/drive')\r\n",
        "os.chdir('/content/drive/My Drive/Wildfire_Challenge/Data')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8oqlgT1fPW4"
      },
      "source": [
        "def get_df_watson(file_name):\r\n",
        "    file = project.get_file(file_name)\r\n",
        "    file.seek(0)\r\n",
        "    return pd.read_csv(file)\r\n",
        "\r\n",
        "wildfires_df = pd.read_csv('Historical_Wildfires.csv')\r\n",
        "weather_df = pd.read_csv('HistoricalWeather.csv')\r\n",
        "forecasts_df = pd.read_csv('HistoricalWeatherForecasts.csv')\r\n",
        "landclass_df = pd.read_csv('LandClass.csv')\r\n",
        "\r\n",
        "forecasts_df['Date'] = pd.to_datetime(forecasts_df['Date'])\r\n",
        "wildfires_df['Date'] = pd.to_datetime(wildfires_df['Date'])\r\n",
        "weather_df['Date'] = pd.to_datetime(weather_df['Date'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LCnGUNKdC6e"
      },
      "source": [
        "##### ADD FIX DATA TO LANDCLASS #####\n",
        "temp_df = pd.DataFrame.drop_duplicates(weather_df[['Region','count()[unit: km^2]']])\n",
        "landclass_df = pd.merge(landclass_df, temp_df)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4h9lHuHdC6f"
      },
      "source": [
        "##### REPLACE ZEROES WITH NAN #####\n",
        "#wildfires_df = wildfires_df.mask(wildfires_df==0)\n",
        "wildfires_df = wildfires_df.drop(columns = ['Replaced', 'Count'])"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwshLZNjdC6g"
      },
      "source": [
        "##### REFORMAT WEATHER DATA #####\n",
        "def reformat_weather_data(df):\n",
        "    df = df.rename(columns={\"count()[unit: km^2]\": \"Area\", \"min()\": \"Min\", \"max()\": \"Max\", \"mean()\": \"Mean\", \"variance()\": \"Variance\"})\n",
        "\n",
        "    # Reformat the data\n",
        "    df_pivot = df.pivot_table(values=['Min','Max','Mean','Variance'], index=['Date','Region'], columns=['Parameter'])\n",
        "    # Reset dataframe index\n",
        "    df_pivot.reset_index(inplace=True)\n",
        "\n",
        "    # Renaming Column names\n",
        "    df_pivot.columns = [col[0] if not(col[1]) else '{1}_{0}'.format(*col) for col in df_pivot.columns.values]\n",
        "\n",
        "    # Rearranging Data and column\n",
        "    params = df_pivot.columns.tolist()[3:]\n",
        "    params.sort()\n",
        "    return df_pivot[df_pivot.columns.tolist()[:3] + params].copy()\n",
        "\n",
        "weather_df = reformat_weather_data(weather_df)\n",
        "forecasts_df = reformat_weather_data(forecasts_df)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoUuNJ5W9PGf"
      },
      "source": [
        "##### FUNCTIONS FOR MISSING VALUES #####\r\n",
        "\r\n",
        "def fill_frames(df, columns):\r\n",
        "    df_all = pd.DataFrame()\r\n",
        "    for region in landclass_df.Region:\r\n",
        "      df_temp = df[df['Region'] == region]\r\n",
        "      df_temp = df_temp.resample('1D', on='Date').first().drop('Date', 1).reset_index()\r\n",
        "      df_temp[['Region']] = df_temp[['Region']].fillna(value = region)\r\n",
        "      df_temp[columns]=df_temp[columns].interpolate(method='linear', direction = 'backward')\r\n",
        "      df_temp = df_temp.fillna(method='ffill')\r\n",
        "      df_temp = df_temp.fillna(method='bfill')\r\n",
        "      df_all = df_all.append(df_temp)\r\n",
        "    return segregate_date(df_all)\r\n",
        "\r\n",
        "def segregate_date(df):\r\n",
        "    #df[\"Day\"] = df[\"Date\"].dt.day\r\n",
        "    df[\"Month\"] = df[\"Date\"].dt.month\r\n",
        "    df[\"Year\"] = df[\"Date\"].dt.year\r\n",
        "    return df"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJessU-pSZbs"
      },
      "source": [
        "##### PREPROCESSING FORECAST_DF ######\r\n",
        "forecasts_df.drop_duplicates(inplace = True)\r\n",
        "forecasts_columns = ['Precipitation_Max', 'Precipitation_Mean', 'Precipitation_Min', 'Precipitation_Variance', 'RelativeHumidity_Max', 'RelativeHumidity_Mean', 'RelativeHumidity_Min', 'RelativeHumidity_Variance', 'SolarRadiation_Max', 'SolarRadiation_Mean', 'SolarRadiation_Min', 'SolarRadiation_Variance', 'Temperature_Max', 'Temperature_Mean', 'Temperature_Min', 'Temperature_Variance', 'WindSpeed_Max', 'WindSpeed_Mean', 'WindSpeed_Min', 'WindSpeed_Variance']\r\n",
        "forecasts_df = fill_frames(forecasts_df, forecasts_columns)\r\n",
        "#KEIN SOILWATER IN FORECAST --> in weather model löschen"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ZVVLlRUxMO"
      },
      "source": [
        "##### PROCESSING DATA #####\r\n",
        "aggr_df = wildfires_df.merge(weather_df, how='left', on=['Date', 'Region'])\r\n",
        "\r\n",
        "aggr_df = aggr_df.set_index(['Date','Region']).fillna(forecasts_df.set_index(['Date','Region'])).reset_index()\r\n",
        "aggr_df.drop(['Std_confidence', 'Var_confidence'], axis=1, inplace = True)\r\n",
        "aggr_columns = ['Estimated_fire_area','Mean_estimated_fire_brightness','Mean_estimated_fire_radiative_power','Mean_confidence','Precipitation_Max','Precipitation_Mean','Precipitation_Min','Precipitation_Variance','RelativeHumidity_Max','RelativeHumidity_Mean','RelativeHumidity_Min','RelativeHumidity_Variance','SoilWaterContent_Max','SoilWaterContent_Mean','SoilWaterContent_Min','SoilWaterContent_Variance','SolarRadiation_Max','SolarRadiation_Mean','SolarRadiation_Min','SolarRadiation_Variance','Temperature_Max','Temperature_Mean','Temperature_Min','Temperature_Variance', 'WindSpeed_Max','WindSpeed_Mean','WindSpeed_Min','WindSpeed_Variance']\r\n",
        "aggr_df = fill_frames(aggr_df, aggr_columns)\r\n",
        "\r\n",
        "#add vegetation data\r\n",
        "aggr_df = aggr_df.merge(landclass_df, how='left', on=['Region'])\r\n",
        "#TOdo: aggr_df wetter erst außen vor und dann erst mit 2014 Daten auffüllen? oder ncícht sinnvoll weil feuerdaten interpoliert"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x4_2aqEdC6n"
      },
      "source": [
        "##### SAVE FILES #####\n",
        "def save_files_watson():\n",
        "  project.save_data(\"Cleansed_Data.csv\", aggr_df.to_csv(index=False), overwrite=True)\n",
        "  project.save_data(\"LandClass.csv\", landclass_df.to_csv(index=False), overwrite=True)\n",
        "  project.save_data(\"Cleansed_Forecasts.csv\", forecasts_df.to_csv(index=False), overwrite=True)\n",
        "\n",
        "aggr_df.to_csv('Cleansed_Data.csv', index = False)\n",
        "landclass_df.to_csv('Cleansed_LandClass.csv', index = False)\n",
        "forecasts_df.to_csv('Cleansed_Forecasts.csv', index = False)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X89iz1RUdC6p"
      },
      "source": [
        "# Download as CSV: data frame, optional title and filename\n",
        "def create_download_link_csv(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
        "    # generate in-memory CSV, then base64-encode it\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
        "    html = html.format(payload=payload,title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "#create_download_link_csv(df_NSW,\"Download my data\",\"NSW.csv\")"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "dF3EQjgPNiYi",
        "outputId": "0d543ec2-9252-48bf-c305-9cd4f612cc40"
      },
      "source": [
        "sample_dict = { 'Date': [10, 20, np.NaN, np.NaN],\r\n",
        "                'Region': [5, np.NaN, np.NaN, 29],\r\n",
        "                'S3': [15, np.NaN, np.NaN, 11],\r\n",
        "                'S4': [21, 22, 23, 25],\r\n",
        "                'Subjects': ['Maths', 'Finance', 'History', 'Geography']}\r\n",
        "df = pd.DataFrame(sample_dict)\r\n",
        "columns = ['Maths', 'Finance', 'History', 'Geography']\r\n",
        "df\r\n",
        "#df.fillna(value=df.mean(), inplace=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Region</th>\n",
              "      <th>S3</th>\n",
              "      <th>S4</th>\n",
              "      <th>Subjects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21</td>\n",
              "      <td>Maths</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22</td>\n",
              "      <td>Finance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23</td>\n",
              "      <td>History</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>29.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>25</td>\n",
              "      <td>Geography</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Date  Region    S3  S4   Subjects\n",
              "0  10.0     5.0  15.0  21      Maths\n",
              "1  20.0     NaN   NaN  22    Finance\n",
              "2   NaN     NaN   NaN  23    History\n",
              "3   NaN    29.0  11.0  25  Geography"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "ZpDR-YJNnvwH",
        "outputId": "168a9a2e-128c-4d0f-f274-6568bf3955ef"
      },
      "source": [
        "data=aggr_df[aggr_df['Region']== 'SA']\r\n",
        "fires_SA = data[['Date' , 'Region','Estimated_fire_area']]\r\n",
        "fires_SA = fires_SA.resample('1D', on='Date').first().drop('Date', 1).reset_index()\r\n",
        "fires_SA[['Region']] = fires_SA[['Region']].fillna(value = 'SA')\r\n",
        "\r\n",
        "\r\n",
        "fires_SA['Date'] = pd.to_datetime(fires_SA['Date'])\r\n",
        "fires_SA.set_index(['Date'])\r\n",
        "#print(fires_SA.head(20))\r\n",
        "#print(\"\\nInterpolate the missing values using the Linear Interpolation method (purch_amt):\")\r\n",
        "#fires_SA['Estimated_fire_area'].interpolate(method='from_derivatives', order=30, inplace=True) #, direction = 'forward'\r\n",
        "\r\n",
        "fires_SA['Fill']= fires_SA['Estimated_fire_area'].fillna((fires_SA['Estimated_fire_area'].fillna(method='ffill') + fires_SA['Estimated_fire_area'].fillna(method='bfill'))/2)\r\n",
        "fires_SA['Fill'].fillna(method='ffill', inplace=True)\r\n",
        "fires_SA['Fill'].fillna(method='bfill', inplace=True)\r\n",
        "fires_SA['Interpolate']=fires_SA['Estimated_fire_area'].interpolate(method='linear',direction = 'backward', inplace=False)\r\n",
        "fires_SA['MA'] = fires_SA['Fill'].rolling(window=5).mean()\r\n",
        "fires_SA['BFILL'] = fires_SA['Estimated_fire_area'].fillna(method='bfill')\r\n",
        "\r\n",
        "mean = fires_SA.mean()\r\n",
        "data = fires_SA.iloc[3000:3400,]\r\n",
        "plt.figure(figsize=(20, 6))\r\n",
        "e = sns.lineplot(x=\"Date\", y=\"Estimated_fire_area\", data=data, color='black')\r\n",
        "e.set_yscale(\"log\")\r\n",
        "plt.figure(figsize=(20, 6))\r\n",
        "g = sns.lineplot(x=\"Date\", y=\"Interpolate\", data=data, color='red')\r\n",
        "g.set_yscale(\"log\")\r\n",
        "plt.figure(figsize=(20, 6))\r\n",
        "h = sns.lineplot(x=\"Date\", y=\"Fill\", data=data,color='orange')\r\n",
        "h.set_yscale(\"log\")\r\n",
        "plt.figure(figsize=(20, 6))\r\n",
        "i = sns.lineplot(x=\"Date\", y=\"MA\", data=data,color='green')\r\n",
        "i.set_yscale(\"log\")\r\n",
        "plt.figure(figsize=(20, 6))\r\n",
        "j = sns.lineplot(x=\"Date\", y=\"BFILL\", data=data,color='pink')\r\n",
        "j.set_yscale(\"log\")\r\n",
        "\r\n",
        "dRan = pd.date_range(start ='1-1-2018', end ='8-01-2018', freq ='D') \r\n",
        "print(fires_SA.isna().sum())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9695e574043a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfires_SA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfires_SA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Estimated_fire_area\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    }
  ]
}